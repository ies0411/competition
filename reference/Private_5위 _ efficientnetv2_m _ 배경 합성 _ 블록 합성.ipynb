{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625fb744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import timm\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import torchvision.models as models\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import date, datetime, timezone, timedelta\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "from copy import deepcopy\n",
    "    \n",
    "exp_day = str(date.today())\n",
    "\n",
    "KST = timezone(timedelta(hours=9))\n",
    "time_record = datetime.now(KST)\n",
    "now = str(time_record)[5:10]+'_'+str(time_record)[11:19]\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "\n",
    "model_name = f\"{os.path.basename(__file__).split('.py')[0]}\"\n",
    "weight_save_path = f\"checkpoints/{model_name}_{now}\"\n",
    "os.makedirs(weight_save_path, exist_ok=True)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"weight save path:{weight_save_path}\")\n",
    "\n",
    "CFG = {\n",
    "    'IMG_SIZE':480,\n",
    "    'EPOCHS':60,\n",
    "    'LEARNING_RATE':0.000001,\n",
    "    'BATCH_SIZE':32,\n",
    "    'SEED':41\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# wandb.init(\n",
    "#     project='02_포디블록구조추출AI경진대회',\n",
    "#     name = f'{model_name}_{now}',\n",
    "#     config = CFG\n",
    "# )\n",
    "\n",
    "\n",
    "class CosineAnnealingWarmUpRestarts(_LRScheduler):\n",
    "    def __init__(self, optimizer, T_0, T_mult=1, eta_max=0.1, T_up=0, gamma=1., last_epoch=-1):\n",
    "        if T_0 <= 0 or not isinstance(T_0, int):\n",
    "            raise ValueError(\"Expected positive integer T_0, but got {}\".format(T_0))\n",
    "        if T_mult < 1 or not isinstance(T_mult, int):\n",
    "            raise ValueError(\"Expected integer T_mult >= 1, but got {}\".format(T_mult))\n",
    "        if T_up < 0 or not isinstance(T_up, int):\n",
    "            raise ValueError(\"Expected positive integer T_up, but got {}\".format(T_up))\n",
    "        self.T_0 = T_0\n",
    "        self.T_mult = T_mult\n",
    "        self.base_eta_max = eta_max\n",
    "        self.eta_max = eta_max\n",
    "        self.T_up = T_up\n",
    "        self.T_i = T_0\n",
    "        self.gamma = gamma\n",
    "        self.cycle = 0\n",
    "        self.T_cur = last_epoch\n",
    "        super(CosineAnnealingWarmUpRestarts, self).__init__(optimizer, last_epoch)\n",
    "    \n",
    "    def get_lr(self):\n",
    "        if self.T_cur == -1:\n",
    "            return self.base_lrs\n",
    "        elif self.T_cur < self.T_up:\n",
    "            return [(self.eta_max - base_lr)*self.T_cur / self.T_up + base_lr for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr + (self.eta_max - base_lr) * (1 + math.cos(math.pi * (self.T_cur-self.T_up) / (self.T_i - self.T_up))) / 2\n",
    "                    for base_lr in self.base_lrs]\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "            self.T_cur = self.T_cur + 1\n",
    "            if self.T_cur >= self.T_i:\n",
    "                self.cycle += 1\n",
    "                self.T_cur = self.T_cur - self.T_i\n",
    "                self.T_i = (self.T_i - self.T_up) * self.T_mult + self.T_up\n",
    "        else:\n",
    "            if epoch >= self.T_0:\n",
    "                if self.T_mult == 1:\n",
    "                    self.T_cur = epoch % self.T_0\n",
    "                    self.cycle = epoch // self.T_0\n",
    "                else:\n",
    "                    n = int(math.log((epoch / self.T_0 * (self.T_mult - 1) + 1), self.T_mult))\n",
    "                    self.cycle = n\n",
    "                    self.T_cur = epoch - self.T_0 * (self.T_mult ** n - 1) / (self.T_mult - 1)\n",
    "                    self.T_i = self.T_0 * self.T_mult ** (n)\n",
    "            else:\n",
    "                self.T_i = self.T_0\n",
    "                self.T_cur = epoch\n",
    "                \n",
    "        self.eta_max = self.base_eta_max * (self.gamma**self.cycle)\n",
    "        self.last_epoch = math.floor(epoch)\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.backbone = timm.create_model('tf_efficientnetv2_m', pretrained=True, num_classes=num_classes)\n",
    "        #self.backbone = timm.create_model('tf_efficientnetv2_m', pretrained=False, num_classes=num_classes)\n",
    "        #self.classifier = nn.Linear(1000, num_classes)\n",
    "        nn.init.xavier_normal_(self.backbone.classifier.weight)\n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.backbone(x))\n",
    "        #x = F.sigmoid(self.classifier(x))\n",
    "        return x\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, transforms=None):\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_path_list[index]\n",
    "        \n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=image)['image']\n",
    "        \n",
    "        if self.label_list is not None:\n",
    "            label = torch.FloatTensor(self.label_list[index])\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)\n",
    "\n",
    "train_transform = A.Compose([\n",
    "                            A.CenterCrop(height=384, width = 384 ,p=1),\n",
    "                            A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "                            \n",
    "                            A.Affine(p=1,translate_percent=[-0.1,0.1],scale = [0.9,1.1],shear = [-10,10], interpolation =cv2.INTER_LINEAR,cval = (255,255,255)),\n",
    "                            A.HorizontalFlip(always_apply=False, p=0.5),\n",
    "                            #A.RandomToneCurve(scale=0.1, always_apply=False, p=0.5),\n",
    "                            A.ColorJitter(brightness=[0.9,1.1], contrast=0.1, saturation=0.1, hue=0.01, p=0.5),\n",
    "                            A.GaussNoise(always_apply=False, p=0.5, var_limit=(0.0, 26.849998474121094)),\n",
    "                            A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "                            A.CenterCrop(height=384, width = 384 ,p=1),\n",
    "                            A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "                            A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "                            \n",
    "                            ToTensorV2()\n",
    "                            ])    \n",
    "\n",
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    \n",
    "    if (device.type == 'cuda') and (torch.cuda.device_count() > 1):\n",
    "        print('Multi GPU activate')\n",
    "        model = nn.DataParallel(model, device_ids = list(range(torch.cuda.device_count())))\n",
    "    model.to(device)\n",
    "    \n",
    "    #model.load_state_dict(torch.load(\"checkpoints/tf_efficientv2_m_16_01-25_03:52:29/tf_efficientv2_m_16_epoch46.pth\"))\n",
    "    \n",
    "    criterion = nn.BCELoss().to(device)\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    best_model = None\n",
    "    best_val_loss = 0.001\n",
    "    best_train_loss = 0.001\n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for imgs, labels in tqdm(iter(train_loader), desc = f\"Train end epoch{CFG['EPOCHS']}\"):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(imgs)\n",
    "            loss = criterion(output, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "        \n",
    "        _val_loss, _val_acc = validation(model, criterion, val_loader, device)\n",
    "        _train_loss = np.mean(train_loss)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val ACC : [{_val_acc:.5f}]')\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            #scheduler.step(_val_loss)\n",
    "            scheduler.step(epoch)\n",
    "            \n",
    "        if best_train_loss > _train_loss:\n",
    "            #best_val_acc = _val_acc\n",
    "            best_train_loss = _train_loss\n",
    "            best_model = model\n",
    "            #torch.save(model.state_dict(), os.path.join(weight_save_path,f\"{model_name}_best_epoch{str(epoch).zfill(2)}.pth\"))\n",
    "        torch.save(model.state_dict(), os.path.join(weight_save_path,f\"{model_name}_epoch{str(epoch).zfill(2)}.pth\"))\n",
    "            \n",
    "#         metrics = {\n",
    "#             \"train/train_loss\" : _train_loss,\n",
    "#             \"train/lr\" : optimizer.param_groups[0]['lr'],\n",
    "#             \"val/val_loss\" : _val_loss,\n",
    "#             \"val/val_acc\" : _val_acc\n",
    "#         }\n",
    "#         wandb.log(metrics)\n",
    "                   \n",
    "            \n",
    "#     wandb.alert(\n",
    "#         title=\"Finish\",\n",
    "#         text=f\"Finish training {model_name}\"\n",
    "#     )\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "def validation(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(iter(val_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            probs = model(imgs)\n",
    "            \n",
    "            loss = criterion(probs, labels)\n",
    "            \n",
    "            probs  = probs.cpu().detach().numpy()\n",
    "            labels = labels.cpu().detach().numpy()\n",
    "            preds = probs > 0.5\n",
    "            batch_acc = (labels == preds).mean()\n",
    "            \n",
    "            val_acc.append(batch_acc)\n",
    "            val_loss.append(loss.item())\n",
    "        \n",
    "        _val_loss = np.mean(val_loss)\n",
    "        _val_acc = np.mean(val_acc)\n",
    "    \n",
    "    return _val_loss, _val_acc\n",
    "\n",
    "def inference(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for imgs in tqdm(iter(test_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            \n",
    "            probs = model(imgs)\n",
    "\n",
    "            probs  = probs.cpu().detach().numpy()\n",
    "            preds = probs > 0.5\n",
    "            preds = preds.astype(int)\n",
    "            predictions += preds.tolist()\n",
    "    return predictions\n",
    "\n",
    "def get_labels(df):\n",
    "    return df.iloc[:,2:].values\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정\n",
    "\n",
    "train_df = pd.read_csv('../data/kfold_csv_1차학습_7/fold1_train.csv')\n",
    "train_df['img_path'] = train_df['img_path'].apply(lambda x:os.path.join(\"../data\",x))\n",
    "\n",
    "val_df = pd.read_csv('../data/kfold_csv_val_5/fold1_val.csv')\n",
    "val_df['img_path'] = val_df['img_path'].apply(lambda x:os.path.join(\"../data\",x))\n",
    "val_df = val_df[val_df.columns[:12]]\n",
    "val_df[val_df.columns[2:12]] = val_df[val_df.columns[2:12]].astype('int')\n",
    "\n",
    "train_labels = get_labels(train_df)\n",
    "val_labels = get_labels(val_df)\n",
    "\n",
    "train_dataset = CustomDataset(train_df['img_path'].values, train_labels, train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=8)\n",
    "\n",
    "val_dataset = CustomDataset(val_df['img_path'].values, val_labels, test_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=8)\n",
    "\n",
    "\n",
    "model = BaseModel()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=30, T_mult=1, eta_max=0.0001,  T_up=10, gamma=0.7)\n",
    "\n",
    "infer_model = train(model, optimizer, train_loader, val_loader, scheduler, device)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
