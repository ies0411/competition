{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error as mse, mean_absolute_error as mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas Version : 1.5.1\n",
      "numpy Version : 1.21.5\n",
      "sklearn Version : 1.1.3\n",
      "lightgbm Version : 3.2.1\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import sklearn\n",
    "import lightgbm\n",
    "\n",
    "print('pandas Version :', pandas.__version__)\n",
    "print('numpy Version :', numpy.__version__)\n",
    "print('sklearn Version :', sklearn.__version__)\n",
    "print('lightgbm Version :', lightgbm.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "def nmae(true, pred):\n",
    "    return mae(true, pred) / 406.22247394653374\n",
    "\n",
    "def permutation_importances(model, vv):\n",
    "    use_features = vv[0].columns\n",
    "    oof = model.predict(vv[0])\n",
    "    base_score = mae(vv[1], oof)\n",
    "\n",
    "    good_features = []\n",
    "    for col in use_features:\n",
    "        test = vv[0].copy()\n",
    "        test[col] = np.random.permutation(test[col])\n",
    "        permu_oof = model.predict(test)\n",
    "        permu_score = mae(vv[1], permu_oof)\n",
    "        if permu_score>base_score:\n",
    "            good_features += [col]\n",
    "    return good_features\n",
    "\n",
    "def main():\n",
    "    \n",
    "    df_train = pd.read_csv('../open/train.csv')\n",
    "    df_test = pd.read_csv('../open/test.csv')\n",
    "    sub = pd.read_csv('../open/sample_submission.csv')\n",
    "    target = '착과량(int)'\n",
    "    \n",
    "\n",
    "    seed_permu_oof = []\n",
    "    seed_permu_prediction = []\n",
    "    seed_ff_oof = []\n",
    "    seed_ff_prediction = []\n",
    "    FOLDS = 10\n",
    "    SEEDS = [42, 1028, 1234, 0, 24]\n",
    "    \n",
    "    for seed in SEEDS:\n",
    "        seed_everything(seed=seed)\n",
    "\n",
    "        kf = KFold(n_splits=FOLDS, random_state=seed, shuffle=True)\n",
    "        splits = list(kf.split(df_train))\n",
    "\n",
    "        drop_cols = ['ID']\n",
    "        drop_cols += [col for col in df_train.columns if '새순' not in col]\n",
    "\n",
    "        feature_importacne_df = pd.DataFrame()\n",
    "        use_cols = [col for col in df_train.columns if col not in drop_cols + [target]]\n",
    "        oof = np.zeros(len(df_train))\n",
    "        prediction = np.zeros(len(df_test))\n",
    "\n",
    "        for fold, (trn_idx, val_idx) in enumerate(splits):\n",
    "            print(f'-------------------------- {fold}/{FOLDS} --------------------------')\n",
    "            tt = (df_train.loc[trn_idx, use_cols], df_train.loc[trn_idx, target])\n",
    "            vv = (df_train.loc[val_idx, use_cols], df_train.loc[val_idx, target])\n",
    "\n",
    "            reg = LGBMRegressor(\n",
    "                            objective='regression',# regression, regression_l1, poisson, poisson\n",
    "                            n_estimators=10000,\n",
    "                            learning_rate=0.01,\n",
    "                            max_depth=-1,\n",
    "                            # num_leaves=64,\n",
    "                            subsample=0.7,\n",
    "                            colsample_bytree=0.3,\n",
    "                            random_state=seed,\n",
    "                            # reg_alpha=0.01,\n",
    "                            # reg_lambda=0.01,\n",
    "                            )\n",
    "            reg.fit(tt[0], tt[1], eval_set=[tt, vv], early_stopping_rounds=200, verbose=500)\n",
    "\n",
    "            permu_features = permutation_importances(reg, vv)\n",
    "            use_cols = permu_features\n",
    "            tt = (df_train.loc[trn_idx, use_cols], df_train.loc[trn_idx, target])\n",
    "            vv = (df_train.loc[val_idx, use_cols], df_train.loc[val_idx, target])\n",
    "            \n",
    "            reg.fit(tt[0], tt[1], eval_set=[tt, vv], early_stopping_rounds=200, verbose=500)\n",
    "\n",
    "            oof[val_idx] = reg.predict(vv[0])\n",
    "            prediction += reg.predict(df_test[use_cols]) / FOLDS\n",
    "            feature_importacne_df = feature_importacne_df.append(pd.DataFrame(zip(use_cols, reg.feature_importances_), columns=['feature', 'value']))\n",
    "\n",
    "        feature_importacne_df = feature_importacne_df.groupby('feature').mean().sort_values('value', ascending=False).reset_index()\n",
    "        print(nmae(df_train[target], oof), mae(df_train[target], oof), mse(df_train[target], oof))\n",
    "        seed_permu_oof += [oof]\n",
    "        seed_permu_prediction += [prediction]\n",
    "\n",
    "    \n",
    "    for seed in SEEDS:\n",
    "        seed_everything(seed=seed)\n",
    "\n",
    "        kf = KFold(n_splits=FOLDS, random_state=seed, shuffle=True)\n",
    "        splits = list(kf.split(df_train))\n",
    "\n",
    "        drop_cols = ['ID']\n",
    "        drop_cols += [col for col in df_train.columns if '새순' not in col]\n",
    "\n",
    "        feature_importacne_df = pd.DataFrame()\n",
    "        use_cols = [col for col in df_train.columns if col not in drop_cols + [target]]\n",
    "        oof = np.zeros(len(df_train))\n",
    "        prediction = np.zeros(len(df_test))\n",
    "\n",
    "        for fold, (trn_idx, val_idx) in enumerate(splits):\n",
    "            print(f'-------------------------- {fold}/{FOLDS} --------------------------')\n",
    "            tt = (df_train.loc[trn_idx, use_cols], df_train.loc[trn_idx, target])\n",
    "            vv = (df_train.loc[val_idx, use_cols], df_train.loc[val_idx, target])\n",
    "\n",
    "            reg = LGBMRegressor(\n",
    "                            objective='regression',# regression, regression_l1, poisson, poisson\n",
    "                            n_estimators=10000,\n",
    "                            learning_rate=0.01,\n",
    "                            max_depth=-1,\n",
    "                            # num_leaves=64,\n",
    "                            subsample=0.7,\n",
    "                            colsample_bytree=0.3,\n",
    "                            random_state=seed,\n",
    "                            # reg_alpha=0.01,\n",
    "                            # reg_lambda=0.01,\n",
    "                            )\n",
    "            reg.fit(tt[0], tt[1], eval_set=[tt, vv], early_stopping_rounds=200, verbose=500)\n",
    "\n",
    "            oof[val_idx] = reg.predict(vv[0])\n",
    "            prediction += reg.predict(df_test[use_cols]) / FOLDS\n",
    "            feature_importacne_df = feature_importacne_df.append(pd.DataFrame(zip(use_cols, reg.feature_importances_), columns=['feature', 'value']))\n",
    "        feature_importacne_df = feature_importacne_df.groupby('feature').mean().sort_values('value', ascending=False).reset_index()\n",
    "\n",
    "        use_cols = feature_importacne_df.iloc[:20, 0].tolist()\n",
    "        oof = np.zeros(len(df_train))\n",
    "        prediction = np.zeros(len(df_test))\n",
    "\n",
    "        for fold, (trn_idx, val_idx) in enumerate(splits):\n",
    "            print(f'-------------------------- {fold}/{FOLDS} --------------------------')\n",
    "            tt = (df_train.loc[trn_idx, use_cols], df_train.loc[trn_idx, target])\n",
    "            vv = (df_train.loc[val_idx, use_cols], df_train.loc[val_idx, target])\n",
    "\n",
    "            lr = LGBMRegressor(\n",
    "                            objective='regression',# regression, regression_l1, poisson\n",
    "                            n_estimators=10000,\n",
    "                            learning_rate=0.01,\n",
    "                            max_depth=-1,\n",
    "                            # num_leaves=64,\n",
    "                            subsample=0.7,\n",
    "                            colsample_bytree=0.3,\n",
    "                            random_state=seed,\n",
    "                            # reg_alpha=0.01,\n",
    "                            # reg_lambda=0.01,\n",
    "                            )\n",
    "            lr.fit(tt[0], tt[1], eval_set=[tt, vv], early_stopping_rounds=200, verbose=500)\n",
    "\n",
    "            oof[val_idx] = lr.predict(vv[0])\n",
    "            prediction += lr.predict(df_test[use_cols]) / FOLDS\n",
    "\n",
    "        seed_ff_oof += [oof]\n",
    "        seed_ff_prediction += [prediction]\n",
    "        \n",
    "    sub[target] = np.mean(seed_permu_prediction, 0)*0.5 + np.mean(seed_ff_prediction, 0)*0.5\n",
    "    sub.to_csv('../submit/submission.csv', index=False)\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('cancer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3f2969ca733e47a31e6f5996b5f4ff91e043faf674edf59ce48899480459694"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
