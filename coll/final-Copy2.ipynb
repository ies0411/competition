{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1db13f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#앙상블\n",
    "# pip uninstall opencv-python-headless==4.5.5.62\n",
    "#pip install opencv-python-headless==4.5.2.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed9ba04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "import albumentations as A\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from segmentation_models_pytorch.losses import FocalLoss\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModel, AutoImageProcessor, AutoConfig\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a95a426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f09879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "all_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0de55a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>video_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>./train/TRAIN_0000.mp4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>./train/TRAIN_0001.mp4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>./train/TRAIN_0002.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>./train/TRAIN_0003.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>./train/TRAIN_0004.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>TRAIN_2693</td>\n",
       "      <td>./train/TRAIN_2693.mp4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694</th>\n",
       "      <td>TRAIN_2694</td>\n",
       "      <td>./train/TRAIN_2694.mp4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>TRAIN_2695</td>\n",
       "      <td>./train/TRAIN_2695.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>TRAIN_2696</td>\n",
       "      <td>./train/TRAIN_2696.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>TRAIN_2697</td>\n",
       "      <td>./train/TRAIN_2697.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2698 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sample_id              video_path  label\n",
       "0     TRAIN_0000  ./train/TRAIN_0000.mp4      7\n",
       "1     TRAIN_0001  ./train/TRAIN_0001.mp4      7\n",
       "2     TRAIN_0002  ./train/TRAIN_0002.mp4      0\n",
       "3     TRAIN_0003  ./train/TRAIN_0003.mp4      0\n",
       "4     TRAIN_0004  ./train/TRAIN_0004.mp4      1\n",
       "...          ...                     ...    ...\n",
       "2693  TRAIN_2693  ./train/TRAIN_2693.mp4      3\n",
       "2694  TRAIN_2694  ./train/TRAIN_2694.mp4      5\n",
       "2695  TRAIN_2695  ./train/TRAIN_2695.mp4      0\n",
       "2696  TRAIN_2696  ./train/TRAIN_2696.mp4      0\n",
       "2697  TRAIN_2697  ./train/TRAIN_2697.mp4      0\n",
       "\n",
       "[2698 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ef3570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CFG = {\n",
    "    'VIDEO_LENGTH':10, \n",
    "    'IMG_SIZE':240,\n",
    "    'EPOCHS':2,\n",
    "    'LEARNING_RATE':1e-5,\n",
    "    'BATCH_SIZE':2,\n",
    "    'SEED':2023,\n",
    "    'SPLIT':5,\n",
    "    'ROOT':'./data',\n",
    "    'MODEL':'MCG-NJU/videomae-base-finetuned-ssv2',\n",
    "    'LOAD_WEIGHT':False,\n",
    "    'LOAD_WEIGHT_NAME' :'a',\n",
    "    'VAL_SCORE_THRES' : 0.98,\n",
    "    'NUM_ASB':1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b42aa213",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits = CFG['SPLIT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee5d0e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['video_path'] = all_df['video_path'].apply(lambda x:CFG['ROOT']+x[1:])\n",
    "test_df['video_path'] = test_df['video_path'].apply(lambda x:CFG['ROOT']+x[1:])\n",
    "\n",
    "crash_df = all_df.copy()\n",
    "crash_df['label'] = crash_df['label'].apply(lambda x: 1 if x != 0 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c402ff1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_df = all_df.copy()\n",
    "idx = ego_df[ego_df['label']==0].index\n",
    "ego_df.drop(idx,inplace=True)\n",
    "\n",
    "ego_df['label'] = ego_df['label'].apply(lambda x: 1 if x < 7 else 0)\n",
    "ego_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d5132b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = all_df.copy()\n",
    "idx = weather_df[weather_df['label']==0].index\n",
    "weather_df.drop(idx,inplace=True)\n",
    "#0:normal,1:snow,2:rain\n",
    "weather_df['label'] = weather_df['label'].apply(lambda x: 0 if x==1 or x==2 or x==7 or x==8 else 1 if x==3 or x==4 or x==8 or x==9 else 2)\n",
    "weather_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e76534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df = all_df.copy()\n",
    "idx = time_df[time_df['label']==0].index\n",
    "time_df.drop(idx,inplace=True)\n",
    "#0:normal,1:snow,2:rain\n",
    "time_df['label'] = time_df['label'].apply(lambda x: 0 if x%2==1 else 1)\n",
    "time_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65e1c289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>video_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>./data/train/TRAIN_0000.mp4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>./data/train/TRAIN_0001.mp4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>./data/train/TRAIN_0002.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>./data/train/TRAIN_0003.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>./data/train/TRAIN_0004.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>TRAIN_2693</td>\n",
       "      <td>./data/train/TRAIN_2693.mp4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694</th>\n",
       "      <td>TRAIN_2694</td>\n",
       "      <td>./data/train/TRAIN_2694.mp4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>TRAIN_2695</td>\n",
       "      <td>./data/train/TRAIN_2695.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>TRAIN_2696</td>\n",
       "      <td>./data/train/TRAIN_2696.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>TRAIN_2697</td>\n",
       "      <td>./data/train/TRAIN_2697.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2698 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sample_id                   video_path  label\n",
       "0     TRAIN_0000  ./data/train/TRAIN_0000.mp4      7\n",
       "1     TRAIN_0001  ./data/train/TRAIN_0001.mp4      7\n",
       "2     TRAIN_0002  ./data/train/TRAIN_0002.mp4      0\n",
       "3     TRAIN_0003  ./data/train/TRAIN_0003.mp4      0\n",
       "4     TRAIN_0004  ./data/train/TRAIN_0004.mp4      1\n",
       "...          ...                          ...    ...\n",
       "2693  TRAIN_2693  ./data/train/TRAIN_2693.mp4      3\n",
       "2694  TRAIN_2694  ./data/train/TRAIN_2694.mp4      5\n",
       "2695  TRAIN_2695  ./data/train/TRAIN_2695.mp4      0\n",
       "2696  TRAIN_2696  ./data/train/TRAIN_2696.mp4      0\n",
       "2697  TRAIN_2697  ./data/train/TRAIN_2697.mp4      0\n",
       "\n",
       "[2698 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b433f3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>video_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>./data/train/TRAIN_0000.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>./data/train/TRAIN_0001.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>./data/train/TRAIN_0004.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0006</td>\n",
       "      <td>./data/train/TRAIN_0006.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0007</td>\n",
       "      <td>./data/train/TRAIN_0007.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>TRAIN_2685</td>\n",
       "      <td>./data/train/TRAIN_2685.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>TRAIN_2689</td>\n",
       "      <td>./data/train/TRAIN_2689.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>TRAIN_2692</td>\n",
       "      <td>./data/train/TRAIN_2692.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>TRAIN_2693</td>\n",
       "      <td>./data/train/TRAIN_2693.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>TRAIN_2694</td>\n",
       "      <td>./data/train/TRAIN_2694.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>915 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sample_id                   video_path  label\n",
       "0    TRAIN_0000  ./data/train/TRAIN_0000.mp4      0\n",
       "1    TRAIN_0001  ./data/train/TRAIN_0001.mp4      0\n",
       "2    TRAIN_0004  ./data/train/TRAIN_0004.mp4      1\n",
       "3    TRAIN_0006  ./data/train/TRAIN_0006.mp4      1\n",
       "4    TRAIN_0007  ./data/train/TRAIN_0007.mp4      0\n",
       "..          ...                          ...    ...\n",
       "910  TRAIN_2685  ./data/train/TRAIN_2685.mp4      0\n",
       "911  TRAIN_2689  ./data/train/TRAIN_2689.mp4      1\n",
       "912  TRAIN_2692  ./data/train/TRAIN_2692.mp4      0\n",
       "913  TRAIN_2693  ./data/train/TRAIN_2693.mp4      1\n",
       "914  TRAIN_2694  ./data/train/TRAIN_2694.mp4      1\n",
       "\n",
       "[915 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ego_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "660a98ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>video_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>./data/train/TRAIN_0000.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>./data/train/TRAIN_0001.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>./data/train/TRAIN_0002.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>./data/train/TRAIN_0003.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>./data/train/TRAIN_0004.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>TRAIN_2693</td>\n",
       "      <td>./data/train/TRAIN_2693.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694</th>\n",
       "      <td>TRAIN_2694</td>\n",
       "      <td>./data/train/TRAIN_2694.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>TRAIN_2695</td>\n",
       "      <td>./data/train/TRAIN_2695.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>TRAIN_2696</td>\n",
       "      <td>./data/train/TRAIN_2696.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>TRAIN_2697</td>\n",
       "      <td>./data/train/TRAIN_2697.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2698 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sample_id                   video_path  label\n",
       "0     TRAIN_0000  ./data/train/TRAIN_0000.mp4      1\n",
       "1     TRAIN_0001  ./data/train/TRAIN_0001.mp4      1\n",
       "2     TRAIN_0002  ./data/train/TRAIN_0002.mp4      0\n",
       "3     TRAIN_0003  ./data/train/TRAIN_0003.mp4      0\n",
       "4     TRAIN_0004  ./data/train/TRAIN_0004.mp4      1\n",
       "...          ...                          ...    ...\n",
       "2693  TRAIN_2693  ./data/train/TRAIN_2693.mp4      1\n",
       "2694  TRAIN_2694  ./data/train/TRAIN_2694.mp4      1\n",
       "2695  TRAIN_2695  ./data/train/TRAIN_2695.mp4      0\n",
       "2696  TRAIN_2696  ./data/train/TRAIN_2696.mp4      0\n",
       "2697  TRAIN_2697  ./data/train/TRAIN_2697.mp4      0\n",
       "\n",
       "[2698 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crash_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4086f5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>video_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>./data/train/TRAIN_0000.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>./data/train/TRAIN_0001.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>./data/train/TRAIN_0004.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0006</td>\n",
       "      <td>./data/train/TRAIN_0006.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0007</td>\n",
       "      <td>./data/train/TRAIN_0007.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>TRAIN_2685</td>\n",
       "      <td>./data/train/TRAIN_2685.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>TRAIN_2689</td>\n",
       "      <td>./data/train/TRAIN_2689.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>TRAIN_2692</td>\n",
       "      <td>./data/train/TRAIN_2692.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>TRAIN_2693</td>\n",
       "      <td>./data/train/TRAIN_2693.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>TRAIN_2694</td>\n",
       "      <td>./data/train/TRAIN_2694.mp4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>915 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sample_id                   video_path  label\n",
       "0    TRAIN_0000  ./data/train/TRAIN_0000.mp4      0\n",
       "1    TRAIN_0001  ./data/train/TRAIN_0001.mp4      0\n",
       "2    TRAIN_0004  ./data/train/TRAIN_0004.mp4      0\n",
       "3    TRAIN_0006  ./data/train/TRAIN_0006.mp4      1\n",
       "4    TRAIN_0007  ./data/train/TRAIN_0007.mp4      0\n",
       "..          ...                          ...    ...\n",
       "910  TRAIN_2685  ./data/train/TRAIN_2685.mp4      0\n",
       "911  TRAIN_2689  ./data/train/TRAIN_2689.mp4      0\n",
       "912  TRAIN_2692  ./data/train/TRAIN_2692.mp4      0\n",
       "913  TRAIN_2693  ./data/train/TRAIN_2693.mp4      1\n",
       "914  TRAIN_2694  ./data/train/TRAIN_2694.mp4      2\n",
       "\n",
       "[915 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "809dd763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>video_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>./data/train/TRAIN_0000.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>./data/train/TRAIN_0001.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>./data/train/TRAIN_0004.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0006</td>\n",
       "      <td>./data/train/TRAIN_0006.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0007</td>\n",
       "      <td>./data/train/TRAIN_0007.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>TRAIN_2685</td>\n",
       "      <td>./data/train/TRAIN_2685.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>TRAIN_2689</td>\n",
       "      <td>./data/train/TRAIN_2689.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>TRAIN_2692</td>\n",
       "      <td>./data/train/TRAIN_2692.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>TRAIN_2693</td>\n",
       "      <td>./data/train/TRAIN_2693.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>TRAIN_2694</td>\n",
       "      <td>./data/train/TRAIN_2694.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>915 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sample_id                   video_path  label\n",
       "0    TRAIN_0000  ./data/train/TRAIN_0000.mp4      0\n",
       "1    TRAIN_0001  ./data/train/TRAIN_0001.mp4      0\n",
       "2    TRAIN_0004  ./data/train/TRAIN_0004.mp4      0\n",
       "3    TRAIN_0006  ./data/train/TRAIN_0006.mp4      0\n",
       "4    TRAIN_0007  ./data/train/TRAIN_0007.mp4      0\n",
       "..          ...                          ...    ...\n",
       "910  TRAIN_2685  ./data/train/TRAIN_2685.mp4      1\n",
       "911  TRAIN_2689  ./data/train/TRAIN_2689.mp4      0\n",
       "912  TRAIN_2692  ./data/train/TRAIN_2692.mp4      0\n",
       "913  TRAIN_2693  ./data/train/TRAIN_2693.mp4      0\n",
       "914  TRAIN_2694  ./data/train/TRAIN_2694.mp4      0\n",
       "\n",
       "[915 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fed98cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58170cb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VideoMAEForVideoClassification were not initialized from the model checkpoint at MCG-NJU/videomae-base-finetuned-ssv2 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([174, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([174]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VideoMAEForVideoClassification were not initialized from the model checkpoint at MCG-NJU/videomae-base-finetuned-ssv2 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([174, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([174]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VideoMAEForVideoClassification were not initialized from the model checkpoint at MCG-NJU/videomae-base-finetuned-ssv2 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([174, 768]) in the checkpoint and torch.Size([3, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([174]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VideoMAEForVideoClassification were not initialized from the model checkpoint at MCG-NJU/videomae-base-finetuned-ssv2 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([174, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([174]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "from transformers import VideoMAEConfig, VideoMAEModel\n",
    "from transformers import AutoImageProcessor, VideoMAEForVideoClassification\n",
    "from transformers import XCLIPVisionModel, XCLIPVisionConfig\n",
    "\n",
    "\n",
    "crash_configuration = VideoMAEConfig()\n",
    "crash_configuration = AutoConfig.from_pretrained(CFG['MODEL'])\n",
    "crash_configuration.num_frames = CFG['VIDEO_LENGTH']\n",
    "crash_configuration.num_frames=CFG['VIDEO_LENGTH']\n",
    "crash_configuration.image_size=CFG['IMG_SIZE']\n",
    "crash_configuration.id2label = {0:'no crash',1:'crash'}\n",
    "crash_configuration.label2id = {'no crash':0,'crash':1}\n",
    "crash_model = VideoMAEForVideoClassification.from_pretrained(CFG['MODEL'],config=crash_configuration,ignore_mismatched_sizes=True)\n",
    "\n",
    "ego_configuration = VideoMAEConfig()\n",
    "ego_configuration = AutoConfig.from_pretrained(CFG['MODEL'])\n",
    "ego_configuration.num_frames = CFG['VIDEO_LENGTH']\n",
    "ego_configuration.num_frames=CFG['VIDEO_LENGTH']\n",
    "ego_configuration.image_size=CFG['IMG_SIZE']\n",
    "ego_configuration.id2label = {0:'other',1:'ego'}\n",
    "ego_configuration.label2id = {'other':0,'ego':1}\n",
    "ego_model = VideoMAEForVideoClassification.from_pretrained(CFG['MODEL'],config=ego_configuration,ignore_mismatched_sizes=True)\n",
    "\n",
    "weather_configuration = VideoMAEConfig()\n",
    "weather_configuration = AutoConfig.from_pretrained(CFG['MODEL'])\n",
    "weather_configuration.num_frames = CFG['VIDEO_LENGTH']\n",
    "weather_configuration.num_frames=CFG['VIDEO_LENGTH']\n",
    "weather_configuration.image_size=CFG['IMG_SIZE']\n",
    "weather_configuration.id2label = {0:'normal',1:'snow',2:'rain'}\n",
    "weather_configuration.label2id = {'normal':0,'snow':1,'rain':2}\n",
    "weather_model = VideoMAEForVideoClassification.from_pretrained(CFG['MODEL'],config=weather_configuration,ignore_mismatched_sizes=True)\n",
    "\n",
    "time_configuration = VideoMAEConfig()\n",
    "time_configuration = AutoConfig.from_pretrained(CFG['MODEL'])\n",
    "time_configuration.num_frames = CFG['VIDEO_LENGTH']\n",
    "time_configuration.num_frames=CFG['VIDEO_LENGTH']\n",
    "time_configuration.image_size=CFG['IMG_SIZE']\n",
    "time_configuration.id2label = {0:'day',1:'night'}\n",
    "time_configuration.label2id = {'normal':0,'snow':1}\n",
    "time_model = VideoMAEForVideoClassification.from_pretrained(CFG['MODEL'],config=time_configuration,ignore_mismatched_sizes=True)\n",
    "\n",
    "\n",
    "image_processor_config = AutoImageProcessor.from_pretrained(CFG['MODEL'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "414e3138",
   "metadata": {},
   "outputs": [],
   "source": [
    "Alb = A.Compose([\n",
    "        A.Resize(width=CFG['IMG_SIZE'], height=CFG['IMG_SIZE']),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomBrightness(p=0.1),\n",
    "#         A.GaussNoise(p=0.2,var_limit=(0.0, 26.849998474121094)).\n",
    "        A.Downscale(p=0.2,scale_min=0.699999988079071, scale_max=0.9900000095367432, interpolation=2),\n",
    "        A.Normalize(mean=tuple(image_processor_config.image_mean)\n",
    "                   ,std=tuple(image_processor_config.image_std))\n",
    "    ], p=1)\n",
    "\n",
    "\n",
    "def aug_video(vid, tfms):\n",
    "    aug_vid = []\n",
    "    for x in vid:\n",
    "        aug_vid.append((tfms(image = np.asarray(x)))['image'])\n",
    "    return torch.from_numpy(np.stack(aug_vid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f3ffee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, video_path_list, label_list,transform=None):\n",
    "        self.video_path_list = video_path_list\n",
    "        self.label_list = label_list\n",
    "        self.Alb = transform\n",
    "    \n",
    "    def get_labels(self):   \n",
    "        return self.label_list  \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        frames = self.get_video(self.video_path_list[index])\n",
    "        if self.label_list is not None:\n",
    "            label = self.label_list[index]\n",
    "            return frames, label\n",
    "        else:\n",
    "            return frames\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.video_path_list)\n",
    "    \n",
    "    def get_video(self, path):\n",
    "        frames = []\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        for idx in range(50):\n",
    "            if idx%5 == 3:\n",
    "                _, img = cap.read()\n",
    "                img = cv2.resize(img, (CFG['IMG_SIZE'], CFG['IMG_SIZE']))\n",
    "                frames.append(img)\n",
    "        if self.Alb is not None:\n",
    "            frames = aug_video(frames, tfms=self.Alb)\n",
    "        return torch.FloatTensor(np.array(frames)).permute(0, 3, 1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05370681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(skf_idx, model, optimizer, train_loader, val_loader, scheduler, device, cls_type):\n",
    "    model.to(device)\n",
    "    criterion = FocalLoss('multiclass')\n",
    "    best_val_score = 0\n",
    "    best_model = None\n",
    "    achieve = False\n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for videos, labels in tqdm(iter(train_loader)):\n",
    "            videos = videos.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(videos)\n",
    "            loss = criterion(output.logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n",
    "        if _val_score > CFG['VAL_SCORE_THRES']:\n",
    "            achieve=True\n",
    "            print(\"archieve score!!\")\n",
    "            break\n",
    "        _train_loss = np.mean(train_loss)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val F1 : [{_val_score:.5f}]')\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(_val_score)\n",
    "            \n",
    "        if best_val_score < _val_score:\n",
    "            best_val_score = _val_score\n",
    "            best_model = model\n",
    "            date=datetime.today().strftime(\"%Y%m%d%H%M%S\")\n",
    "            torch.save(best_model.state_dict(), './'+cls_type + '_' + str(skf_idx) +'_'+ date + '_best_model.pth')\n",
    "        skf_idx+=1\n",
    "    return best_model,achieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51fa21fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    preds, trues = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for videos, labels in tqdm(iter(val_loader)):\n",
    "            videos = videos.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            output = model(videos)\n",
    "            \n",
    "            loss = criterion(output.logits, labels)\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "            \n",
    "            preds += output.logits.argmax(1).detach().cpu().numpy().tolist()\n",
    "            trues += labels.detach().cpu().numpy().tolist()\n",
    "        \n",
    "        _val_loss = np.mean(val_loss)\n",
    "    \n",
    "    _val_score = f1_score(trues, preds, average='macro')\n",
    "    return _val_loss, _val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e07fda77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pl = []\n",
    "\n",
    "crash = {\n",
    "    'model' : crash_model,\n",
    "    'cls_type' : 'crash',\n",
    "    'df' : crash_df\n",
    "}\n",
    "\n",
    "ego = {\n",
    "    'model' : ego_model,\n",
    "    'cls_type' : 'ego',\n",
    "    'df' : ego_df\n",
    "}\n",
    "\n",
    "weather = {\n",
    "    'model' : weather_model,\n",
    "    'cls_type' : 'weather',\n",
    "    'df' : weather_df\n",
    "}\n",
    "\n",
    "time = {\n",
    "    'model' : time_model,\n",
    "    'cls_type' : 'time',\n",
    "    'df' : time_df\n",
    "}\n",
    "\n",
    "dict_pl.append(crash)\n",
    "dict_pl.append(ego)\n",
    "dict_pl.append(weather)\n",
    "dict_pl.append(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b731a4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total_idx\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      7\u001b[0m     model \u001b[38;5;241m=\u001b[39m dict_name[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel : \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m dict_name[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcls_type\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m     apply_df \u001b[38;5;241m=\u001b[39m dict_name[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/anaconda3/envs/competition/lib/python3.8/site-packages/torch/nn/modules/module.py:1455\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1453\u001b[0m \u001b[38;5;66;03m# copy state_dict so _load_from_state_dict can modify it\u001b[39;00m\n\u001b[1;32m   1454\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(state_dict, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1455\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mstate_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1457\u001b[0m     \u001b[38;5;66;03m# mypy isn't aware that \"_metadata\" exists in state_dict\u001b[39;00m\n\u001b[1;32m   1458\u001b[0m     state_dict\u001b[38;5;241m.\u001b[39m_metadata \u001b[38;5;241m=\u001b[39m metadata  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "\n",
    "# if CFG['LOAD_WEIGHT'] == True:\n",
    "checkpoint = './checkpoint/crash/crash_120230221015333_best_model.pth'\n",
    "\n",
    "\n",
    "# for total_idx,dict_name in enumerate(dict_pl):\n",
    "#     if total_idx==0:\n",
    "model = dict_name['model']\n",
    "crash_model.load_state_dict(checkpoint)\n",
    "print('model : '+ dict_name['cls_type'])\n",
    "apply_df = dict_name['df'].copy()\n",
    "cls_type = dict_name['cls_type']\n",
    "# optimizer = torch.optim.Adadelta(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "# scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=[lambda1, lambda2], verbose=True)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3,threshold_mode='abs',min_lr=1e-12, verbose=True)\n",
    "skf_idx=1\n",
    "for train_idx,val_idx in skf.split(apply_df['video_path'],apply_df['label']):\n",
    "    train_dataset = VideoDataset(apply_df['video_path'][train_idx].values, apply_df['label'][train_idx].values,transform=Alb)\n",
    "    val_dataset = VideoDataset(apply_df['video_path'][val_idx].values, apply_df['label'][val_idx].values, transform=Alb)\n",
    "    train_loader = DataLoader(train_dataset,sampler=ImbalancedDatasetSampler(train_dataset),shuffle=False,batch_size = CFG['BATCH_SIZE'],  num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], num_workers=4)\n",
    "    dict_name['model'],achieve = train(skf_idx,model, optimizer, train_loader, val_loader, scheduler, device, cls_type)\n",
    "#         skf_idx+=1\n",
    "    if achieve == True:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344b9363",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd895bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = VideoDataset(test_df['video_path'].values,label_list= None, transform=Alb)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False,batch_size = CFG['BATCH_SIZE'],  num_workers=4)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d95f675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for videos in tqdm(iter(test_loader)):\n",
    "            videos = videos.to(device)\n",
    "            output = model(videos)\n",
    "            preds += output.logits.argmax(1).detach().cpu().numpy().tolist()\n",
    "#             preds += output.logits.detach().cpu().numpy().tolist()\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef7a712",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('./checkpoint/crash/crash_120230221015333_best_model.pth')\n",
    "crash_model.load_state_dict(checkpoint)\n",
    "\n",
    "checkpoint = torch.load('./checkpoint/ego/ego_120230221021140_best_model.pth')\n",
    "ego_model.load_state_dict(checkpoint)\n",
    "\n",
    "checkpoint = torch.load('./checkpoint/weather/weather_2_20230221022225_best_model.pth')\n",
    "weather_model.load_state_dict(checkpoint)\n",
    "\n",
    "checkpoint = torch.load('./checkpoint/time/time_1_20230221093311_best_model.pth')\n",
    "time_model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f55d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_preds_list = []\n",
    "crash_preds_list=[]\n",
    "ego_preds_list=[]\n",
    "weather_preds_list=[]\n",
    "time_preds_list=[]\n",
    "crash_preds=None\n",
    "ego_preds=None\n",
    "weather_preds=None\n",
    "time_preds=None\n",
    "\n",
    "for idx in range(CFG['NUM_ASB']):\n",
    "    crash_preds = inference(crash_model, test_loader, device)\n",
    "#     crash_preds_list.append(crash_preds)\n",
    "    \n",
    "#TODO :앙상블\n",
    "\n",
    "for idx in range(CFG['NUM_ASB']):\n",
    "    ego_preds = inference(ego_model, test_loader, device)\n",
    "#     ego_preds_list.append(ego_preds)\n",
    "    \n",
    "for idx in range(CFG['NUM_ASB']):\n",
    "    weather_preds = inference(weather_model, test_loader, device)\n",
    "#     weather_preds_list.append(weather_preds)\n",
    "    \n",
    "for idx in range(CFG['NUM_ASB']):\n",
    "    time_preds = inference(time_model, test_loader, device)\n",
    "#     time_preds_list.append(time_preds)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bdd37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crash_preds_df = pd.DataFrame(crash_preds,columns=['crash'])\n",
    "# ego_preds_df = pd.DataFrame(ego_preds,columns=['ego'])\n",
    "# weather_preds_df = pd.DataFrame(weather_preds,columns=['weather'])\n",
    "# time_preds_df = pd.DataFrame(time_preds,columns=['time'])\n",
    "\n",
    "preds=[]\n",
    "\n",
    "print(len(crash_preds))\n",
    "print(len(ego_preds))\n",
    "print(len(weather_preds))\n",
    "print(len(time_preds))\n",
    "\n",
    "for idx,crash in enumerate(crash_preds):\n",
    "    ego = ego_preds[idx]\n",
    "    weather = weather_preds[idx]\n",
    "    time = time_preds[idx]\n",
    "    if crash == 0:\n",
    "        preds.append(0)\n",
    "    else:\n",
    "        if ego==0:\n",
    "            if weather==0:\n",
    "                if time == 0:\n",
    "                    preds.append(7)\n",
    "                else:\n",
    "                    preds.append(8)\n",
    "            elif weather==1:\n",
    "                if time == 0:\n",
    "                    preds.append(9)\n",
    "                else:\n",
    "                    preds.append(10)\n",
    "            else:\n",
    "                if time == 0:\n",
    "                    preds.append(11)\n",
    "                else:\n",
    "                    preds.append(12)\n",
    "                    \n",
    "        else:\n",
    "            if weather==0:\n",
    "                if time == 0:\n",
    "                    preds.append(1)\n",
    "                else:\n",
    "                    preds.append(2)\n",
    "            elif weather==1:\n",
    "                if time == 0:\n",
    "                    preds.append(3)\n",
    "                else:\n",
    "                    preds.append(4)\n",
    "            else:\n",
    "                if time == 0:\n",
    "                    preds.append(5)\n",
    "                else:\n",
    "                    preds.append(6)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08667a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3866596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['label'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c08b94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8ef3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "date=datetime.today().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "submit.to_csv('./'+date+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec2b292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
